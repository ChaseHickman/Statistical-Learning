---
title: "Test Statistics"
output: github_document
---

> Test statistics are generally a ratio comparing variance **between** groups to variance **within** groups. When the ratio is large we conclude they must be from different populations.

### t values in Linear Regression

In the summary below, t values are a ratio of estimated coefficients to their standard error (variance within group). The intercept t value of 13.63 is significantly larger than 1, and quantified by the p-value (Pr>|t| or the probability of obtaining an absolute t value greater than 13.63).

```{r message=FALSE, warning=FALSE}

summary(
  lm(formula = Sepal.Length ~ Sepal.Width, data = iris)
  )

```

Calculate the p-value manually using a cumulative probability distribution, the t value,
and the model degrees-of-freedom:

```{r echo=TRUE}
pt(q = c(abs(13.63)), df = 148, lower.tail = FALSE)
```

Student's T distribution is used because it is more conservative in the tails when n < 30. When n > 30 it behaves similar to the normal distribution.

```{r message=FALSE, warning=FALSE}
library(tidyverse)

ggplot() +
  geom_line(aes(x = seq(from = -5, to =20, length.out = 100), 
                y = pt(q = seq(from = -5, to =20, length.out = 100), 
                df = 148, 
                lower.tail = FALSE))) +
  geom_point(aes(x = 13.63, 
                 y = pt(q = c(abs(13.63)), 
                 df = 148, 
                 lower.tail = FALSE)), 
             color = 'blue', 
             alpha = .5, 
             size = 3, 
             shape = 2) +
  xlab(label = 't value') +
  ylab(label = 'cum. probability in upper tail')

```

### Degrees of Freedom
> The degree to which the model is free to move about or vary.

Degrees of freedom in the model are the number of data-points minus the number of estimated coefficients.

E.g. if I have 7 hats and wear a different hat each day of the week, I have six degrees of freedom because,
on the final day, I have no choice in which hat to wear.